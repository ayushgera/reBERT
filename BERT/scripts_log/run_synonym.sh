python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0005_1_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0005_1_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0005_3_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0005_3_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0005_5_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0005 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0005_5_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_1e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_1e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_1e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_1e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_1e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 1e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_1e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-05_1_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-05_1_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-05_3_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-05_3_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-05_5_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-05 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-05_5_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0001_1_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0001_1_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0001_3_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0001_3_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0001_5_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 0.0001 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_0.0001_5_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-06_1_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 1 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-06_1_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-06_3_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 3 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-06_3_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.1 --max_answer_length 15 --output_dir experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-06_5_0.1_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.3.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python run-reBERT.py --bert_model experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.3 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.3
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.3/predictions.json experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.3/eval_result
rm experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.3/pytorch_model.bin
python run-reBERT.py --bert_model experiment/bert-base-uncased-squad-model-v1.1/ --do_train --do_lower_case --train_file data/newsqa/newsqa_singleSynonymQuestions_0.5.json --learning_rate 5e-06 --vocab_file data/newsqa/vocab.txt --num_train_epochs 5 --max_seq_length 192 --max_query_length 32 --warmup_proportion 0.2 --max_answer_length 15 --output_dir experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python run-reBERT.py --bert_model experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.5 --do_predict --do_lower_case --predict_file data/newsqa/test.json --output_dir experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.5
python evaluate-reBERT.py data/newsqa/test.json experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.5/predictions.json experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.5/eval_result
rm experiment/192_32_5e-06_5_0.2_15_newsqa_singleSynonymQuestions_0.5/pytorch_model.bin
